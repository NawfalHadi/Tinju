{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_data(pose):\n",
    "    print(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "GRAY = (200, 200, 200)\n",
    "PINK = (98, 57, 237)\n",
    "PURPLE = (105, 40, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotJab = True\n",
    "isNotLeftHook = True\n",
    "isNotStraight = True\n",
    "isNotRightHook = True\n",
    "isNotLeftUppercut = True\n",
    "isNotRightUppercut = True\n",
    "isNotGuard = True\n",
    "isNotGuardLeftBody = True\n",
    "isNotGuardRightBody = True\n",
    "isNotIdle = True\n",
    "\n",
    "isSlipLeft = False\n",
    "isSlipRight = False\n",
    "isDucking = False\n",
    "\n",
    "isPause = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pose_detection(self, Jab = True, Straight = True, LeftHook = True,\n",
    "                    RightHook = True, LeftUppercut = True,\n",
    "                    RightUppercut = True, Guard = True, Idle = True,\n",
    "                    GuardLeftBody = True, GuardRightBody = True, SlipL = False, SlipR = False):\n",
    "\n",
    "    isNotJab = Jab\n",
    "    isNotStraight = Straight\n",
    "    isNotLeftHook = LeftHook\n",
    "    isNotRightHook = RightHook\n",
    "    isNotLeftUppercut = LeftUppercut\n",
    "    isNotRightUppercut = RightUppercut\n",
    "    isNotGuard = Guard\n",
    "    isNotGuardLeftBody = GuardLeftBody\n",
    "    isNotGuardRightBody = GuardRightBody\n",
    "    isNotIdle = Idle\n",
    "    isSlipLeft = SlipL\n",
    "    isSlipRight = SlipR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_horizontal_panel(image, shoulderR, shoulderL, nose):\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    left_line = (int(shoulderL.x * width) - 10, 0), (int(shoulderL.x * width) - 10, height)\n",
    "    right_line = (int(shoulderR.x * width) + 10, 0), (int(shoulderR.x * width) + 10, height)\n",
    "    \n",
    "    noseX = nose.x * width\n",
    "    noseRight = left_line[0][0] - (noseX)\n",
    "    noseLeft = right_line[0][0] - (noseX)   \n",
    "    \n",
    "    if noseRight > 0 and not isSlipRight:\n",
    "        # send_data(\"Slip_Right\")\n",
    "        update_pose_detection(SlipR=True)\n",
    "    elif noseLeft < 0 and not isSlipLeft:\n",
    "        # send_data(\"Slip_Left\")\n",
    "        update_pose_detection(SlipL=True)\n",
    "    elif not noseRight > 0 and not noseLeft < 0:\n",
    "        isSlipLeft = False\n",
    "        isSlipRight = False\n",
    "        \n",
    "\n",
    "    cv2.line(image, left_line[0], left_line[1], GREEN, 3)\n",
    "    cv2.line(image, right_line[0], right_line[1], GREEN, 3)\n",
    "\n",
    "    return left_line, right_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vertical_panel(image, nose, hip, elbow_l, elbow_r):\n",
    "    height, width, _ = image.shape\n",
    "    top_offset = 25\n",
    "    bottom_offset = 120\n",
    "\n",
    "    noseY = int(nose.y * height)\n",
    "    hipY = int(hip.y * height)\n",
    "\n",
    "    elbowL_y = int(elbow_l.y * height)\n",
    "    elbowR_y = int(elbow_r.y * height)\n",
    "\n",
    "    hip_elbowL = elbowL_y - hipY + 70\n",
    "    hip_elbowR = elbowR_y - hipY + 70\n",
    "\n",
    "    if not isDucking:\n",
    "        if hip_elbowL > 0  or hip_elbowR > 0:\n",
    "            if hip_elbowL > 0 and hip_elbowR > 0:\n",
    "                if hip_elbowL > hip_elbowR and isNotGuardLeftBody:\n",
    "                    try:\n",
    "                        send_data(\"Guard_LeftBody\")\n",
    "                        update_pose_detection(GuardLeftBody=False)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                elif hip_elbowR > hip_elbowL and isNotGuardRightBody:\n",
    "                    send_data(\"Guard_RightBody\")\n",
    "                    update_pose_detection(GuardRightBody=False)\n",
    "            elif hip_elbowL > 0 and isNotGuardLeftBody:\n",
    "                send_data(\"Guard_LeftBody\")\n",
    "                update_pose_detection(GuardLeftBody=False)\n",
    "            elif hip_elbowR > 0 and isNotGuardRightBody:\n",
    "                send_data(\"Guard_RightBody\")\n",
    "                update_pose_detection(GuardRightBody=False)\n",
    "        elif hip_elbowL < 0 and hip_elbowR < 0:\n",
    "            isNotGuardLeftBody = True\n",
    "            isNotGuardRightBody = True\n",
    "\n",
    "    hip_line = (0, hipY - 70), (width, hipY - 70)\n",
    "    top_y = (0, noseY - 130), (width, noseY - 130)\n",
    "    bottom_y = (0, noseY + 260), (width, noseY + 260)\n",
    "\n",
    "    maxHeight = top_y[0][1]\n",
    "    maxBottom = int(height) - int(bottom_y[0][1])\n",
    "\n",
    "    if (maxHeight < 0):\n",
    "        # print(\"Log : Paused Game\")\n",
    "        top_line = (0, (noseY  + maxHeight) + top_offset ), (width, (noseY + maxHeight) + top_offset)\n",
    "        bottom_line = (0, noseY + bottom_offset), (width, noseY + bottom_offset)\n",
    "        # bottom_line = (0, (noseY  + maxHeight) + bottom_offset ), (width, maxHeight - bottom_offset)\n",
    "    else:\n",
    "        # print(\"Log : Game Running\")\n",
    "        \n",
    "        if(maxBottom < 0):\n",
    "            # print(\"Log : Duck\")\n",
    "            top_line = (0, (noseY + maxBottom )), (width, (noseY + maxBottom))\n",
    "            bottom_line = (0, noseY + bottom_offset), (width, noseY + bottom_offset)\n",
    "            isDucking = True\n",
    "            # bottom_line = (0, (noseY + maxBottom ) + bottom_offset), (width, (noseY + maxBottom) + bottom_offset)\n",
    "        else:\n",
    "            top_line = (0, noseY + top_offset), (width, noseY + top_offset)\n",
    "            bottom_line = (0, noseY + bottom_offset), (width, noseY + bottom_offset)\n",
    "            isDucking = False\n",
    "\n",
    "    cv2.line(image, top_line[0], top_line[1], GREEN, 3)\n",
    "    cv2.line(image, bottom_line[0], bottom_line[1], GREEN, 3)\n",
    "\n",
    "    cv2.line(image, top_y[0], top_y[1], RED, 2)\n",
    "    cv2.line(image, bottom_y[0], bottom_y[1], RED, 2)\n",
    "\n",
    "    cv2.line(image, hip_line[0], hip_line[1], RED, 1)\n",
    "\n",
    "    return top_line, bottom_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line_and_calculate_gap(image, start_point, end_point):\n",
    "    if start_point and end_point:\n",
    "        x1, y1 = start_point.x * image.shape[1], start_point.y * image.shape[0]\n",
    "        x2, y2 = end_point.x * image.shape[1], end_point.y * image.shape[0]\n",
    "        \n",
    "        # Calculate normalized coordinates\n",
    "        gap_x = (x2 - x1) / image.shape[1]\n",
    "        gap_y = (y2 - y1) / image.shape[0]\n",
    "\n",
    "        # Draw line\n",
    "        x1, y1 = int(x1), int(y1)\n",
    "        x2, y2 = int(x2), int(y2)\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "        gap_landmark = landmark_pb2.NormalizedLandmark()\n",
    "        gap_landmark.x = gap_x\n",
    "        gap_landmark.y = gap_y\n",
    "\n",
    "        return gap_landmark\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(probability=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(probability=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../Model/svm_mpgap.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prediction(body_language_class):\n",
    "    if body_language_class == \"Jab\" and isNotJab:\n",
    "        update_pose_detection(Jab=False)\n",
    "        if isDucking:\n",
    "            send_data(\"Low_Jab\")\n",
    "        else:\n",
    "            send_data(\"Jab\")\n",
    "        print(isNotJab)\n",
    "                    \n",
    "    elif body_language_class == \"Straight\" and isNotStraight:\n",
    "        update_pose_detection(Straight=False)\n",
    "        if isDucking:\n",
    "            send_data(\"Low_Straight\")\n",
    "        else:\n",
    "            send_data(\"Straight\")        \n",
    "                    \n",
    "    elif body_language_class == \"Left_Hook\" and isNotLeftHook:\n",
    "        update_pose_detection(LeftHook=False)\n",
    "        if isDucking:\n",
    "            send_data(\"Left_BodyHook\")\n",
    "        else:\n",
    "            send_data(\"Left_Hook\")\n",
    "\n",
    "    elif body_language_class == \"Right_Hook\" and isNotRightHook:\n",
    "        update_pose_detection(RightHook=False)\n",
    "        if isDucking:\n",
    "            send_data(\"Right_BodyHook\")\n",
    "        else:\n",
    "            send_data(\"Right_Hook\")\n",
    "\n",
    "    elif body_language_class == \"Left_Uppercut\" and isNotLeftUppercut:\n",
    "        update_pose_detection(LeftUppercut=False)\n",
    "        send_data(\"Left Uppercut\")\n",
    "\n",
    "    elif body_language_class == \"Right_Uppercut\" and isNotRightUppercut:\n",
    "        update_pose_detection(RightUppercut=False)\n",
    "        send_data(\"Right_Uppercut\")\n",
    "\n",
    "    elif body_language_class == \"Guard\" and isNotGuard:\n",
    "        update_pose_detection(Guard=False)\n",
    "        send_data(\"Guard\")\n",
    "\n",
    "    elif body_language_class == \"Idle\" and isNotIdle:\n",
    "        update_pose_detection(Idle=False)\n",
    "        send_data(\"Idle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluasi_model(file, pose_limit, poses):\n",
    "    cap = cv2.VideoCapture(f'Scenario/{file}')\n",
    "\n",
    "    counter = 0\n",
    "    recent_pose = None\n",
    "\n",
    "    pose_sequence = poses\n",
    "    pose_detected = []\n",
    "    condition = []\n",
    "\n",
    "    print(pose_limit)\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False        \n",
    "        \n",
    "            # Make Detections\n",
    "            results = holistic.process(image)\n",
    "\n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True   \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "\n",
    "            # Get specific landmarks\n",
    "            # Get specific landmarks\n",
    "            nose = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE]\n",
    "            wrist_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_WRIST]\n",
    "            elbow_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_ELBOW]\n",
    "            wrist_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "            elbow_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_ELBOW]\n",
    "\n",
    "            # Use For Making Guideline Purpose\n",
    "            shoulder_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_SHOULDER]\n",
    "            shoulder_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_SHOULDER]\n",
    "            hip = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_HIP]\n",
    "\n",
    "            show_landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            show_landmark_list.landmark.extend([nose, wrist_l, wrist_r, elbow_l, elbow_r, hip])\n",
    "            \n",
    "            # Draw landmarks\n",
    "            for landmark in show_landmark_list.landmark:\n",
    "                x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])\n",
    "            cv2.circle(image, (x, y), 5, (255, 0, 0), -1)\n",
    "\n",
    "            \"\"\"\n",
    "            IT GIVES THE LOCATION OF THE CENTER BASED OFF \n",
    "            THE NOSE X,Y FROM THE FRAMES\n",
    "            \"\"\"\n",
    "\n",
    "            wristL_x, wristL_y = int(wrist_l.x * image.shape[1]), int(wrist_l.y * image.shape[0])\n",
    "            wristR_x, wristR_y = int(wrist_r.x * image.shape[1]), int(wrist_r.y * image.shape[0])\n",
    "            \n",
    "            left_line, right_line = draw_horizontal_panel(image, shoulder_l, shoulder_r, nose)\n",
    "            top_line, bottom_line = draw_vertical_panel(image, nose, hip, elbow_l, elbow_r)\n",
    "            \n",
    "            # Below this is temporary for drawing the line, and we need the calculation of the gap\n",
    "            wristL_horGap = (wristL_x, wristL_y), (left_line[0][0], wristL_y)\n",
    "            wristR_horGap = (wristR_x, wristR_y), (right_line[0][0], wristR_y)\n",
    "            \n",
    "            wristL_verGap = (wristL_horGap[0]), (wristL_x, top_line[0][1])\n",
    "            wristR_verGap = (wristR_horGap[0]), (wristR_x, top_line[0][1])\n",
    "\n",
    "            left_line_x, left_line_y = wristL_horGap[1]\n",
    "            right_line_x, right_line_y = wristR_horGap[1]\n",
    "\n",
    "            \" Wrist Left \"                \n",
    "            wristL_x, wristL_y = wristL_horGap[0]\n",
    "\n",
    "            # Horizontal Gap\n",
    "            # make it so it has a (+ and - value)\n",
    "            wristL_leftLine = wristL_x - left_line_x\n",
    "            wristL_rightLine = wristL_x -right_line_x\n",
    "            \n",
    "            cv2.line(image, wristL_horGap[0], wristL_horGap[1], PINK, 4)\n",
    "            cv2.line(image, wristL_horGap[0], (right_line[0][0], wristL_y + 20), PINK, 4)\n",
    "\n",
    "            # Vertical Gap\n",
    "            wristL_topLine = wristL_y - top_line[0][1]\n",
    "            wristL_bottomLine = bottom_line[0][1] - wristL_y\n",
    "\n",
    "\n",
    "            cv2.line(image, wristL_verGap[0], wristL_verGap[1] , PURPLE, 4)\n",
    "            cv2.line(image, wristL_verGap[0], (wristL_x, bottom_line[0][1]), PURPLE, 4)\n",
    "            \n",
    "            wristLeft_leftTopLine_landmark = landmark_pb2.NormalizedLandmark()\n",
    "            wristLeft_leftTopLine_landmark.x = wristL_leftLine\n",
    "            wristLeft_leftTopLine_landmark.y = wristL_topLine\n",
    "\n",
    "            wristLeft_rightBottomLine_landmark = landmark_pb2.NormalizedLandmark()\n",
    "            wristLeft_rightBottomLine_landmark.x = wristL_rightLine\n",
    "            wristLeft_rightBottomLine_landmark.y = wristL_bottomLine\n",
    "\n",
    "            \" Wrist Right \"\n",
    "            wristR_x, wristR_y = wristR_horGap[0]\n",
    "\n",
    "            # Horizontal Gap\n",
    "            wristR_leftLine = wristR_x - left_line_x\n",
    "            wristR_rightLine = wristR_x - right_line_x\n",
    "\n",
    "            cv2.line(image, wristR_horGap[0], wristR_horGap[1] , PINK, 4)\n",
    "            cv2.line(image, wristR_horGap[0], (left_line[0][0], wristR_y + 20) , PINK, 4)\n",
    "\n",
    "            #Vertical Gap\n",
    "            wristR_topLine = wristR_y - top_line[0][1]\n",
    "            wristR_bottomLine = bottom_line[0][1] - wristR_y\n",
    "\n",
    "            cv2.line(image, wristR_verGap[0], wristR_verGap[1], PURPLE, 4)\n",
    "            cv2.line(image, wristR_verGap[0], (wristR_x, bottom_line[0][1]), PURPLE, 4)\n",
    "\n",
    "            wristRight_leftTopLine_landmark = landmark_pb2.NormalizedLandmark()\n",
    "            wristRight_leftTopLine_landmark.x = wristR_leftLine\n",
    "            wristRight_leftTopLine_landmark.y = wristR_topLine\n",
    "\n",
    "            wristRight_rightBottomLine_landmark = landmark_pb2.NormalizedLandmark()\n",
    "            wristRight_rightBottomLine_landmark.x = wristR_rightLine    \n",
    "            wristRight_rightBottomLine_landmark.y = wristR_bottomLine\n",
    "\n",
    "            # Drawing line and calculating gap for left wrist\n",
    "            gap_nose_left = draw_line_and_calculate_gap(image, nose, wrist_l)\n",
    "\n",
    "            # Drawing line and calculating gap for right wrist\n",
    "            gap_nose_right = draw_line_and_calculate_gap(image, nose, wrist_r)\n",
    "\n",
    "\n",
    "            new_lm = landmark_pb2.NormalizedLandmarkList()\n",
    "            new_lm.landmark.extend([wrist_l, wrist_r, elbow_l, elbow_r,\n",
    "                                    gap_nose_right, gap_nose_left, \n",
    "                                    wristLeft_leftTopLine_landmark, wristLeft_rightBottomLine_landmark, \n",
    "                                    wristRight_leftTopLine_landmark, wristRight_rightBottomLine_landmark\n",
    "                                    ])\n",
    "\n",
    "\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Pose landmarks\n",
    "                pose = new_lm.landmark\n",
    "                pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "        \n",
    "                pose_detected = pd.DataFrame([pose_row])\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "                body_language_class = model.predict(pose_detected)[0]\n",
    "                body_language_prob = model.predict_proba(pose_detected)[0]\n",
    "            \n",
    "                prob = round(body_language_prob[np.argmax(body_language_prob)],2)\n",
    "\n",
    "                if not isSlipLeft and not isSlipRight and isNotGuardLeftBody and isNotGuardRightBody:\n",
    "                        if prob > 0.75:\n",
    "                            send_prediction(body_language_class)\n",
    "                \n",
    "                        # if body_language_class != recent_pose:\n",
    "                        #     recent_pose = body_language_class.split(' ')[0]\n",
    "                            \n",
    "                        #     condition.append(poses[0] == recent_pose)\n",
    "                        #     pose_detected.append(recent_pose)\n",
    "                            \n",
    "                            \n",
    "                        #     print(recent_pose, counter)\n",
    "                        #     counter += 1\n",
    "\n",
    "                # if counter == pose_limit:\n",
    "                #     cap.release()\n",
    "                #     cv2.destroyAllWindows()\n",
    "                #     return pose_detected, condition\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during prediction: {e}\")\n",
    "                        \n",
    "            cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ SCENARIO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'isDucking' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m file \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m pose \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 13\u001b[0m evaluated \u001b[38;5;241m=\u001b[39m \u001b[43mevaluasi_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpose\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluated)\n\u001b[0;32m     16\u001b[0m modified_row \u001b[38;5;241m=\u001b[39m row \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetected\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m evaluated[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m evaluated[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[37], line 59\u001b[0m, in \u001b[0;36mevaluasi_model\u001b[1;34m(file, pose_limit, poses)\u001b[0m\n\u001b[0;32m     56\u001b[0m wristR_x, wristR_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(wrist_r\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mint\u001b[39m(wrist_r\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     58\u001b[0m left_line, right_line \u001b[38;5;241m=\u001b[39m draw_horizontal_panel(image, shoulder_l, shoulder_r, nose)\n\u001b[1;32m---> 59\u001b[0m top_line, bottom_line \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_vertical_panel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melbow_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melbow_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Below this is temporary for drawing the line, and we need the calculation of the gap\u001b[39;00m\n\u001b[0;32m     62\u001b[0m wristL_horGap \u001b[38;5;241m=\u001b[39m (wristL_x, wristL_y), (left_line[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], wristL_y)\n",
      "Cell \u001b[1;32mIn[33], line 15\u001b[0m, in \u001b[0;36mdraw_vertical_panel\u001b[1;34m(image, nose, hip, elbow_l, elbow_r)\u001b[0m\n\u001b[0;32m     12\u001b[0m hip_elbowL \u001b[38;5;241m=\u001b[39m elbowL_y \u001b[38;5;241m-\u001b[39m hipY \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m     13\u001b[0m hip_elbowR \u001b[38;5;241m=\u001b[39m elbowR_y \u001b[38;5;241m-\u001b[39m hipY \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43misDucking\u001b[49m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hip_elbowL \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;129;01mor\u001b[39;00m hip_elbowR \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hip_elbowL \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hip_elbowR \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'isDucking' referenced before assignment"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')    \n",
    "\n",
    "with open('Scenario/scenario.csv', 'r') as csvfile, open(f'Tested/{timestamp}.csv', 'w', newline='') as outfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = list(reader)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for row in data:\n",
    "        scenario = row[0]\n",
    "        file = row[1]\n",
    "        pose = row[2:]\n",
    "\n",
    "        evaluated = evaluasi_model(file, len(pose)-1, pose)\n",
    "        print(evaluated)\n",
    "    \n",
    "        modified_row = row + ['detected'] + evaluated[0] + ['condition'] + evaluated[1]\n",
    "        writer.writerow(modified_row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_12_1_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
